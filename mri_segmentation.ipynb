{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJdb52jeWAFD"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets download -d mateuszbuda/lgg-mri-segmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3oQHbtrBWC6a"
      },
      "outputs": [],
      "source": [
        "!unzip lgg-mri-segmentation.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "JpsKgxncWYL2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "bBxaQWBvWFEA"
      },
      "outputs": [],
      "source": [
        "train_images=[]\n",
        "train_masked_images=[]\n",
        "\n",
        "for patinet_files in  os.listdir('/content/kaggle_3m'):\n",
        "  if patinet_files.startswith('TCGA'):\n",
        "    for images in  os.listdir('/content/kaggle_3m/'+patinet_files):\n",
        "      if images.endswith('_mask.tif'):\n",
        "        train_masked_images.append('/content/kaggle_3m/'+patinet_files+'/'+images)\n",
        "        train_images.append('/content/kaggle_3m/'+patinet_files+'/'+images.replace('_mask',''))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "bOVnxrheaqd3"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def pre_images(image_path):\n",
        "    image = Image.open(image_path)\n",
        "    image = image.resize((256, 256))\n",
        "    image = np.array(image)\n",
        "    image = image / 255.0\n",
        "    return image\n",
        "\n",
        "pre_train_masked_images = []\n",
        "pre_train_images = []\n",
        "\n",
        "for image_path in train_masked_images[:500]:\n",
        "    pre_train_masked_images.append(pre_images(image_path))\n",
        "\n",
        "for image_path in train_images[:500]:\n",
        "    pre_train_images.append(pre_images(image_path))\n",
        "\n",
        "pre_train_masked_images = np.array(pre_train_masked_images)\n",
        "pre_train_images = np.array(pre_train_images)\n",
        "\n",
        "train_images, test_images, train_masked_images, test_masked_images = train_test_split(pre_train_images, pre_train_masked_images, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "tl7sFm7FgkGK"
      },
      "outputs": [],
      "source": [
        "pre_train_images=np.expand_dims(train_images,axis=-1)\n",
        "pre_train_masked_images=np.expand_dims(train_masked_images,axis=-1)\n",
        "\n",
        "pre_test_images=np.expand_dims(test_images,axis=-1)\n",
        "pre_test_masked_images=np.expand_dims(test_masked_images,axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iUqnCvRjHZmr"
      },
      "outputs": [],
      "source": [
        "pre_test_images[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cE0ZucDIE7QR"
      },
      "outputs": [],
      "source": [
        "# make sure i have  only 1 and zero in the masked image\n",
        "import numpy as np\n",
        "unique_values = np.unique(pre_train_masked_images)\n",
        "print(f\"Unique values in pre_train_masked_images: {unique_values}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8tuuIXAq3xeF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "num_images = 4\n",
        "random_indices = np.random.randint(0, len(pre_train_images), size=num_images)\n",
        "\n",
        "fig, axes = plt.subplots(2, 4, figsize=(15, 8))\n",
        "\n",
        "for idx, i in enumerate(random_indices):\n",
        "    axes[0, idx].imshow(pre_train_images[i].squeeze())\n",
        "    axes[0, idx].set_title(f\" image \")\n",
        "    axes[0, idx].axis('off')\n",
        "\n",
        "    axes[1, idx].imshow(pre_train_masked_images[i].squeeze(), cmap=\"gray\")\n",
        "    axes[1, idx].set_title(f\"Mask\")\n",
        "    axes[1, idx].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n3WTIpdRfdWm"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "inputs = tf.keras.layers.Input(shape=(256, 256, 3))\n",
        "\n",
        "conv1 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', name='conv1_1')(inputs)\n",
        "conv1 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', name='conv1_2')(conv1)\n",
        "pool1 = tf.keras.layers.MaxPooling2D((2, 2), name='pool1')(conv1)\n",
        "\n",
        "conv2 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='conv2_1')(pool1)\n",
        "conv2 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='conv2_2')(conv2)\n",
        "pool2 = tf.keras.layers.MaxPooling2D((2, 2), name='pool2')(conv2)\n",
        "\n",
        "conv3 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same', name='conv3_1')(pool2)\n",
        "conv3 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same', name='conv3_2')(conv3)\n",
        "pool3 = tf.keras.layers.MaxPooling2D((2, 2), name='pool3')(conv3)\n",
        "\n",
        "conv4 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same', name='conv4_1')(pool3)\n",
        "conv4 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same', name='conv4_2')(conv4)\n",
        "pool4 = tf.keras.layers.MaxPooling2D((2, 2), name='pool4')(conv4)\n",
        "\n",
        "conv5 = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='conv5_1')(pool4)\n",
        "conv5 = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='conv5_2')(conv5)\n",
        "\n",
        "up6 = tf.keras.layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same', name='up6')(conv5)\n",
        "merge6 = tf.keras.layers.concatenate([up6, conv4], name='merge6')\n",
        "conv6 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same', name='conv6_1')(merge6)\n",
        "conv6 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same', name='conv6_2')(conv6)\n",
        "\n",
        "up7 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same', name='up7')(conv6)\n",
        "merge7 = tf.keras.layers.concatenate([up7, conv3], name='merge7')\n",
        "conv7 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same', name='conv7_1')(merge7)\n",
        "conv7 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same', name='conv7_2')(conv7)\n",
        "\n",
        "up8 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same', name='up8')(conv7)\n",
        "merge8 = tf.keras.layers.concatenate([up8, conv2], name='merge8')\n",
        "conv8 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='conv8_1')(merge8)\n",
        "conv8 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='conv8_2')(conv8)\n",
        "\n",
        "up9 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same', name='up9')(conv8)\n",
        "merge9 = tf.keras.layers.concatenate([up9, conv1], name='merge9')\n",
        "conv9 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', name='conv9_1')(merge9)\n",
        "conv9 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', name='conv9_2')(conv9)\n",
        "\n",
        "outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid', name='outputs')(conv9)\n",
        "\n",
        "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w1AJiPudFMnn"
      },
      "outputs": [],
      "source": [
        "initial_learning_rate = 0.0001\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=initial_learning_rate)\n",
        "\n",
        "def scheduler(epoch, lr):\n",
        "    if epoch % 10 == 0 and epoch != 0:\n",
        "        return lr * 0.1\n",
        "    else:\n",
        "        return lr\n",
        "\n",
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(pre_train_images, pre_train_masked_images, epochs=30,validation_data=[test_images,test_masked_images], batch_size=1, callbacks=[lr_scheduler])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GRE8egAbWEZC"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "model = tf.keras.models.load_model('/content/drive/MyDrive/MyModel_Segmentation_MRI_2.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kAa_6nHXoLhD"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "for i in range(100):\n",
        "    test_image = pre_train_images[i]\n",
        "    test_mask = pre_train_masked_images[i]\n",
        "    predicted_mask = model.predict(np.expand_dims(test_image, axis=0))[0]\n",
        "\n",
        "    plt.figure(figsize=(15, 5))\n",
        "\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.imshow(np.squeeze(test_image))\n",
        "    plt.title('Original Image')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.imshow(test_mask)\n",
        "    plt.title('Ground Truth Mask')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.imshow(predicted_mask)\n",
        "    plt.title('Predicted Mask')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}